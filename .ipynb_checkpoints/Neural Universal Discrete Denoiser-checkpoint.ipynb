{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Universal Discrete Denosier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tasup Moon\n",
    "\n",
    "##### Seonwoo Min, Byunghan Lee, Sungroh Yoon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - we presnet a new framework of applying deep neural networks (DNN) to devise a universal discrete denoiser.\n",
    " - 우리는 DUDE를 고안하기 위해 DNN을 적용한 새로운 프레임 워크를 선보인다.\n",
    " \n",
    " \n",
    " \n",
    " - Unlike other approaches that utilize superviesd learning for denoising, we do not require any addtional training data.\n",
    " - 노이즈 제거를 위해 지도 학습 방법을 사용하던 다른 접근법들과는 달리, 새로운 프레임 워크는 추가적인 훈련 데이터를 필요로 하지 않는다.\n",
    " \n",
    " \n",
    " - In such setting, while the ground-truth label, i.e, the clean data, is not available, we devise \"pesudo-labels\" and a novel objective function such that DNN can be trained in a same way as supervised learning to become a discrete denoiser.\n",
    " - 이러한 환경속에서, 실제 정답 라벨, 즉 깨끗한 데이터는 사용할 수 없지만, 우리는 \"pesudo-labels\"과 DNN이 DUDE와 같은 방식으로 학습될 수 있게하는 새로운 목적 함수를 고안한다.\n",
    " \n",
    " \n",
    " - We experimentally show that our resulting algorithm, dubbed as Neural DUDE, significantly outperforms the previous state-of-the-art in several applications with a systematic rule of choosing the hyperparameter, which is an attractive feature in practice.\n",
    " - 경험적으로 Neural DUDE라고 불리우는, 우리의 결과물인 이 알고리즘은 하이퍼 마라피터를 선택하는 체계적인 규칙으로 여러 적용 분야에서 뛰어난 성능을 보여준다.\n",
    " \n",
    " \n",
    " \n",
    "#### 참고\n",
    "**presudo-labels : 레이블이 없는 데이터로 예측을 수행한 뒤 예측된 레이블이 진짜 레이블인 것처럼해서 모델을 튜닝**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 &nbsp; Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Cleaning noise-corrupted data, i.e., denoising, is a ubiquotous problem in signal processing and machine learning.\n",
    " - 노이즈로  인해 발생하는 데이터, 즉 Denoising은 신호 처리 및 기계 학습 분야에서 유비쿼터스적인 문제이다.\n",
    " \n",
    " \n",
    " \n",
    " - Discrete denoising, in particular, focuses on the cases in which both the underlying clean and noisy data take their values in some finite set.\n",
    " - 특히, 이산형 잡음 제거에서는 특정 유한 집합에서 근본적으로는 깨끗하지만, 노이즈가 있는 데이터에 초점을 맞춘다.\n",
    " \n",
    "\n",
    "\n",
    " - Such setting covers several applications in different domains, such as image denoising [1, 2], DNA sequence denoising [3], and channel decoding [4].\n",
    " - 이런 설정들은, 이미지 잡음 제거, DNA 서열 잡음 제거, 채널 디코딩과 같은 서로 다른 도메인 적용 분야에서 사용된다.\n",
    " \n",
    " \n",
    " \n",
    " #### 참고\n",
    "**ubiquotous : 언제 어디서나 존재하는**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - A conventional approach for addressing the denoising problem is the Bayesian approach, which can often yield a computationally efficient algorithm with reasonable performance.\n",
    " - 잡음 제거 문제를 해결하기 위한 일반적인 접근법은 합리적인 성능을 가진 효율적인 계산 알고리즘을 산출할 수 있는 베이지안 접근법이다.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " - However, limitations can arise when the assumed stochastic models do not accurately reflect the real data distribution.\n",
    " \n",
    "\n",
    " - Particularly, while the models for the noise can often be obtained relatively reliably, obtaining the accurate model for the original clean data is mort tricky; the model for the clean data may be wrong, changing, or may not exist at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - In order to alleviate the above mentioned limitations, [5] proposed a universal approach for discrete denoising.\n",
    " \n",
    " \n",
    " - Namely, the first considered a gnenral setting that the clean finite-valued source symbols are corrupted by a discrete memoryless channel (DMC), a noise mechanism that corrupts each source symbol indeoendently and statistically identically.\n",
    " \n",
    " \n",
    " - Then, they deviesed an algorithm called DUDE(DIscrete Universal DEnoiser) and showed regirious preformance guarantees for the *semi-stochastic setting;* namely, that where no stochatic modeling assumptions are mate on the underlying source data, while the corruption mechanism is assumed to be governed by a *known* DMC.\n",
    " \n",
    " \n",
    " - DUDE is shown to *universally* attain the optimum denoising performance for any source data as the data size grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - In addition to the strong theoretical performance gurantee, DUDE cna be implemented as a computaionally efficient sliding window deniser; hance, it has been successfully applied and extended to some practical applications, e.g., [1,3,4,2].\n",
    " \n",
    " \n",
    " - However, it also had limitations; namely, the performance is sensitive on the choice of sliding window size *k*, becomes large and the alphabet size of the signal increased, DUDE, suffers from the data sparisty problem, which significantly deteriorates the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - In this paper, we present a novel framework of addressing above limitations of DUDE by adopting the machinerire of deep neural networks (DNN) [6], which recently have seen great empirical success in many practical applications.\n",
    " \n",
    " \n",
    " - While there have been some previous attempts of applying neural networks to grayscale image denosing [7,8], they all remained in supervised larning setting. i.e., large-scale training data that the consists of clean and noisy image pairs was necessary.\n",
    " \n",
    " \n",
    " - Such approach requres significant computation resources and training time and is not always transferable to other denoising applications, in which collecting massive training data is often expensive, e.g., DNA sequence denosing [9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Henceforth, we stick to the setting of DUDE, which requires no additional data other than the given noisy data. In this case, however, it is not straightforward to adopt DNN since there is no ground-truth label for supervised training of the networks. Namely, the target label that a denoising algorithm is trying to estimate from the observation is the underlying clean signal, hence, it can never be observed to the algorithm. \n",
    " \n",
    " \n",
    " - Therefore, we carefully exploit the known DMC assumption and the finiteness of the data values, and devise “pseudo-labels” for training DNN. They are based on the unbiased estimate of the true loss a denoising algorithm is incurring, and we show that it is possible to train a DNN as a universal discrete denoiser using the devised pseudo-labels and generalized cross-entropy objective function. \n",
    " \n",
    " \n",
    " - As a by-product, we also obtain an accurate estimator of the true denoising performance, with which we can systematically choose the appropriate window size k. \n",
    " \n",
    " - In results, we experimentally verify that our DNN based denoiser, dubbed as Neural DUDE, can achieve significantly better performance than DUDE maintaining robustness with respect to k.\n",
    " \n",
    " \n",
    " - Furthermore, we note that although the work in this paper is focused on discrete denoising, we believe the proposed framework can be extended to the denoising of continuous-valued signal as well, and we defer it to the future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 &nbsp; Notations and related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 &nbsp; Problem setting of discrete denosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Throughout this paper, we will generally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
